import { NextResponse } from "next/server";
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY, // í™˜ê²½ ë³€ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
});

export async function POST(req) {
  try {
    // âœ… í”„ë¡ íŠ¸ì—ì„œ ì „ë‹¬ëœ í”„ë¡¬í”„íŠ¸ ë°›ê¸°
    const { prompt } = await req.json();

    // âœ… OpenAI í˜¸ì¶œ (í”„ë¡¬í”„íŠ¸ ê·¸ëŒ€ë¡œ ì „ë‹¬)
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini-2024-07-18",
      messages: [
        {
          role: "system",
          content: "ë„ˆëŠ” ì‚¬ìš©ìê°€ ë³´ë‚¸ í”„ë¡¬í”„íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì¶©ì‹¤íˆ ë”°ë¥´ëŠ” AIì•¼. ì ˆëŒ€ ë³€í˜•í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ë°˜ì˜í•´.",
        },
        {
          role: "user",
          content: prompt, // í”„ë¡ íŠ¸ì˜ í”„ë¡¬í”„íŠ¸ ì „ì²´ ê·¸ëŒ€ë¡œ ì „ë‹¬
        },
      ],
      temperature: 0.8,
      max_tokens: 2000,
    });

    const result = completion.choices[0].message.content;
    return NextResponse.json({ result });
  } catch (error) {
    console.error("ğŸ”¥ ê¸€ ìƒì„± ì¤‘ ì˜¤ë¥˜:", error);
    return NextResponse.json(
      { error: "ê¸€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", details: error.message },
      { status: 500 }
    );
  }
}
