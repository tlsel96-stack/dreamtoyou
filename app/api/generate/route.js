import { NextResponse } from "next/server";
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY, // âœ… ë°˜ë“œì‹œ .env.localì— í‚¤ ë„£ê¸°
});

export async function POST(req) {
  try {
    // í”„ë¡ íŠ¸ì—ì„œ ì „ë‹¬ëœ í”„ë¡¬í”„íŠ¸ ë°›ê¸°
    const { prompt } = await req.json();

    // âœ… OpenAI í˜¸ì¶œ
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini-2024-07-18", // ìµœì‹  ëª¨ë¸ ì‚¬ìš©
      messages: [
        {
          role: "system",
          content:
            "ë„ˆëŠ” ë¸”ë¡œê·¸ ì „ë¬¸ ì‘ê°€ì•¼. ì•„ë˜ í”„ë¡¬í”„íŠ¸ ì§€ì‹œë¥¼ ì¶©ì‹¤íˆ ë”°ë¥´ê³  ìì—°ìŠ¤ëŸ½ê²Œ SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ ë³¸ë¬¸ì„ ì‘ì„±í•´ì¤˜.",
        },
        {
          role: "user",
          content: prompt, // ì „ì²´ í”„ë¡¬í”„íŠ¸ë¥¼ í†µì§¸ë¡œ ì „ë‹¬
        },
      ],
      temperature: 0.8,
      max_tokens: 1500,
    });

    // âœ… ê²°ê³¼ ì¶”ì¶œ
    const result = completion.choices[0].message.content;

    // âœ… í”„ë¡ íŠ¸ë¡œ ê²°ê³¼ ë°˜í™˜
    return NextResponse.json({ result });
  } catch (error) {
    console.error("ğŸ”¥ API ì˜¤ë¥˜ ë°œìƒ:", error);
    return NextResponse.json(
      {
        error: "ê¸€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        details: error.message,
      },
      { status: 500 }
    );
  }
}
